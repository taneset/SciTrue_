# ðŸ”¬ SciTrue: Towards Trustworthy Scientific Claim Verification with Transparent Attribution

## Overview

**SciTrue** is a novel system for scientific claim verification that emphasizes **transparent attribution**, **source-level traceability**, and **auditable outputs**. Unlike general-purpose LLMs or retrieval-augmented generation (RAG) tools, SciTrue is purpose-built for domains where accuracy and trustworthiness matterâ€”such as **science**, **journalism**, and **policy**.

---

## ðŸš§ Background

Current LLM-based toolsâ€”like GPT-4.1, Gemini Flash, and LLaMA-3â€”struggle with:

- âŒ Hallucinated or unverifiable citations  
- âŒ Shallow or incomplete source mapping  
- âŒ Slow, verbose, or rigid output formats  
- âŒ Poor context awareness and scholarly rigor  

Even search-integrated models (e.g., GPT-4o-search-preview, Perplexity Sonar Pro) fall short in **attribution fidelity**, making it difficult for users to **audit or trust** the information presented.

---

## âœ… What Makes SciTrue Different

### ðŸ”— End-to-End Scientific Traceability
Each claim is **explicitly grounded** in a verifiable scientific sourceâ€”not just a plausible citation.

### ðŸŽ¯ Superior Attribution Quality
Human evaluation shows **95â€“100% reliability** in SciTrueâ€™s outputs, compared to **10â€“86%** from other leading LLMs across:
- Factual accuracy
- Label consistency
- Context relevance
- Scholarly credibility

### âš¡ Efficient & Flexible Output
- Fast, interactive verification
- Minimal verbosity
- Clear UI and API-ready formatting


### ðŸ”’ Built for High-Stakes Domains
Ideal for:
- Researchers and scientists
- Investigative journalists
- Policymakers and analysts

---

## ðŸ’¡ Why It Matters

> Without precise, reproducible attribution, AI-generated knowledge is just polished speculation.

SciTrue enables users to **verify**, **replicate**, and **challenge** AI-generated claimsâ€”restoring **scientific integrity** and trust.

---



